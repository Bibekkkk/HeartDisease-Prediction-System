# -*- coding: utf-8 -*-
"""Copy of Heart Diseases Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qHywEq974nM-geJX147kzZGdhdNTZKcq

Importing The Libraries
"""

import pandas as pd
import numpy as np

"""Importing The Dataset"""

data = pd.read_csv('/content/drive/MyDrive/Ml/Heart Diseases Prediction/heartdata.csv')

"""Checking Missing Values"""

data.isnull().sum()

"""Checking Duplicate Values"""

duplicate = data.duplicated().any()

duplicate

data = data.drop_duplicates()

duplicate = data.duplicated().any()

duplicate

"""Data Preprocessing"""

nummeric_val=[]
cate_val=[]

for column in data.columns:
    if data[column].nunique()<=10:
        cate_val.append(column)
    else:
      nummeric_val.append(column)

cate_val

nummeric_val

"""Encoding Ctegorical Values"""

cate_val

data['cp'].unique()

cate_val.remove('sex')
cate_val.remove('target')
data = pd.get_dummies(data,columns=cate_val,drop_first=True)

data.head()

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler

st = StandardScaler()
data[nummeric_val]=st.fit_transform(data[nummeric_val])

data.head()

"""Spliting into Training Set And Test Set"""

x = data.drop('target',axis=1)

y = data['target']

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

x_test

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

log = LogisticRegression()
log.fit(x_train,y_train)

y_predic = log.predict(x_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_predic)

"""Support Vector Mechine"""

from sklearn import svm

svm = svm.SVC()

svm.fit(x_train,y_train)

y_precdic = svm.predict(x_test)

accuracy_score(y_test,y_precdic)

"""ANN"""

import tensorflow as tf

ann = tf.keras.models.Sequential()

ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

ann.fit(x_train,y_train,batch_size=32,epochs = 100)